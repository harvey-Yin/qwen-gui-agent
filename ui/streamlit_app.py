"""
Streamlit Chat Interface for GUI-Agent
Provides a user-friendly chat interface for interacting with the agent.
"""
import streamlit as st
import time
import base64
from io import BytesIO
from PIL import Image
import threading
from typing import Optional

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from agent.orchestrator import Orchestrator, Step, TaskResult
from llm.ollama_client import OllamaClient


def decode_base64_image(b64_string: str) -> Image.Image:
    """Decode base64 string to PIL Image."""
    image_data = base64.b64decode(b64_string)
    return Image.open(BytesIO(image_data))


def init_session_state():
    """Initialize Streamlit session state."""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "orchestrator" not in st.session_state:
        st.session_state.orchestrator = Orchestrator()
    if "is_running" not in st.session_state:
        st.session_state.is_running = False
    if "current_steps" not in st.session_state:
        st.session_state.current_steps = []


def check_llm_connection() -> bool:
    """Check if Ollama is accessible."""
    client = OllamaClient()
    return client.test_connection()


def run_agent_task(task: str):
    """Run agent task and update session state."""
    st.session_state.is_running = True
    st.session_state.current_steps = []
    
    def on_step(step: Step):
        st.session_state.current_steps.append(step)
    
    orchestrator = Orchestrator(on_step_callback=on_step)
    result = orchestrator.run_task(task)
    
    st.session_state.is_running = False
    return result


def main():
    st.set_page_config(
        page_title="GUI Agent",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    # Custom CSS
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        padding: 1rem 0;
    }
    .status-box {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .status-running {
        background-color: #fff3cd;
        border: 1px solid #ffc107;
    }
    .status-success {
        background-color: #d4edda;
        border: 1px solid #28a745;
    }
    .status-error {
        background-color: #f8d7da;
        border: 1px solid #dc3545;
    }
    .thought-box {
        background-color: #e3f2fd;
        padding: 0.75rem;
        border-radius: 0.5rem;
        border-left: 4px solid #2196f3;
        margin: 0.5rem 0;
    }
    .action-box {
        background-color: #f3e5f5;
        padding: 0.75rem;
        border-radius: 0.5rem;
        border-left: 4px solid #9c27b0;
        margin: 0.5rem 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    init_session_state()
    
    # Header
    st.markdown('<p class="main-header">ğŸ¤– GUI Agent</p>', unsafe_allow_html=True)
    st.markdown("åŸºäº Qwen3-VL çš„æ™ºèƒ½ GUI è‡ªåŠ¨åŒ–ä»£ç†")
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        
        # Connection status
        if check_llm_connection():
            st.success("âœ… Ollama è¿æ¥æ­£å¸¸")
        else:
            st.error("âŒ æ— æ³•è¿æ¥ Ollama")
            st.info("è¯·ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ")
        
        st.divider()
        
        # Settings
        st.subheader("ä»£ç†è®¾ç½®")
        max_steps = st.slider("æœ€å¤§æ­¥æ•°", 5, 50, 20)
        step_delay = st.slider("æ­¥éª¤é—´éš” (ç§’)", 0.1, 2.0, 0.5)
        
        st.divider()
        
        # Instructions
        st.subheader("ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. åœ¨èŠå¤©æ¡†è¾“å…¥ä»»åŠ¡
        2. ä»£ç†ä¼šæˆªå›¾åˆ†æå±å¹•
        3. è‡ªåŠ¨æ‰§è¡Œ GUI æ“ä½œ
        4. æŸ¥çœ‹æ‰§è¡Œè¿‡ç¨‹å’Œç»“æœ
        
        **ç¤ºä¾‹ä»»åŠ¡:**
        - æ‰“å¼€è®°äº‹æœ¬
        - æ‰“å¼€æµè§ˆå™¨è®¿é—®ç™¾åº¦
        - æ‰“å¼€è®¡ç®—å™¨å¹¶è®¡ç®— 1+1
        """)
        
        st.divider()
        
        # Stop button
        if st.session_state.is_running:
            if st.button("ğŸ›‘ åœæ­¢æ‰§è¡Œ", type="primary"):
                st.session_state.orchestrator.stop()
                st.session_state.is_running = False
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ’¬ å¯¹è¯")
        
        # Display chat history
        chat_container = st.container()
        with chat_container:
            for msg in st.session_state.messages:
                with st.chat_message(msg["role"]):
                    st.write(msg["content"])
                    if "steps" in msg:
                        with st.expander(f"æŸ¥çœ‹æ‰§è¡Œæ­¥éª¤ ({len(msg['steps'])} æ­¥)"):
                            for step in msg["steps"]:
                                st.markdown(f"**æ­¥éª¤ {step.step_number}**")
                                st.markdown(f'<div class="thought-box">ğŸ’­ {step.thought}</div>', 
                                          unsafe_allow_html=True)
                                st.markdown(f'<div class="action-box">ğŸ¯ {step.action_type}: {step.action_result}</div>',
                                          unsafe_allow_html=True)
        
        # Chat input
        if prompt := st.chat_input("è¾“å…¥ä»»åŠ¡...", disabled=st.session_state.is_running):
            # Add user message
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("user"):
                st.write(prompt)
            
            # Run agent
            with st.chat_message("assistant"):
                with st.spinner("ğŸ¤– ä»£ç†æ‰§è¡Œä¸­..."):
                    result = run_agent_task(prompt)
                
                if result.success:
                    st.success(f"âœ… {result.message}")
                else:
                    st.error(f"âŒ {result.message}")
                
                st.info(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {result.total_time:.1f}ç§’, æ­¥éª¤æ•°: {len(result.steps)}")
                
                # Show steps
                if result.steps:
                    with st.expander("æŸ¥çœ‹æ‰§è¡Œæ­¥éª¤"):
                        for step in result.steps:
                            st.markdown(f"**æ­¥éª¤ {step.step_number}**")
                            col_a, col_b = st.columns([1, 1])
                            with col_a:
                                st.markdown(f"ğŸ’­ **æ€è€ƒ:** {step.thought}")
                            with col_b:
                                st.markdown(f"ğŸ¯ **åŠ¨ä½œ:** {step.action_type}")
                                st.markdown(f"ğŸ“ **ç»“æœ:** {step.action_result}")
            
            # Save assistant message
            st.session_state.messages.append({
                "role": "assistant",
                "content": result.message,
                "steps": result.steps
            })
    
    with col2:
        st.subheader("ğŸ“¸ å®æ—¶çŠ¶æ€")
        
        # Show current screenshot
        if st.session_state.current_steps:
            latest_step = st.session_state.current_steps[-1]
            try:
                img = decode_base64_image(latest_step.screenshot_b64)
                st.image(img, caption=f"æ­¥éª¤ {latest_step.step_number} æˆªå›¾", use_container_width=True)
            except Exception as e:
                st.warning(f"æ— æ³•æ˜¾ç¤ºæˆªå›¾: {e}")
        else:
            st.info("æ‰§è¡Œä»»åŠ¡åå°†æ˜¾ç¤ºå±å¹•æˆªå›¾")
        
        # Current status
        if st.session_state.is_running:
            st.markdown('<div class="status-box status-running">â³ æ‰§è¡Œä¸­...</div>', 
                       unsafe_allow_html=True)
            if st.session_state.current_steps:
                step = st.session_state.current_steps[-1]
                st.markdown(f"**å½“å‰æ­¥éª¤:** {step.step_number}")
                st.markdown(f"**æ€è€ƒ:** {step.thought[:100]}...")


if __name__ == "__main__":
    main()
